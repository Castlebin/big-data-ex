package flink.transformation;

import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.streaming.api.datastream.ConnectedStreams;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.co.CoMapFunction;
import org.apache.flink.util.Collector;
import org.junit.jupiter.api.Test;

/**
 * https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/datastream/operators/overview/
 */
public class TransformationTest01 {

    /**
     * 1. map æ“ä½œ    1 -> 1 æ˜ å°„
     */
    @Test
    public void map() throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStreamSource<Long> source = env.fromSequence(1, 10);
        source
                .map(x -> x * x)
                .print();

        env.execute("map");
    }

    /**
     * 2. flatMap æ“ä½œ    1 -> n æ˜ å°„ , n å¯ä»¥æ˜¯å¤šä¸ªï¼Œä¹Ÿå¯ä»¥æ˜¯ 1 ä¸ªï¼Œè¿˜å¯ä»¥æ˜¯ 0 ï¼Œä¸å›ºå®š
     */
    @Test
    public void flatMap() throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStreamSource<Long> source = env.fromSequence(1, 10);
        source            // ä¸€é”®è½¬ä¸º lambda è¡¨è¾¾å¼å±…ç„¶æŠ¥é”™ï¼Œç±»å‹æ¨æ–­å¤±è´¥ï¼Œå·®åŠ²ğŸ‘ğŸ»
                .flatMap(new FlatMapFunction<Long, String>() {
                    @Override
                    public void flatMap(Long aLong, Collector<String> collector) throws Exception {
                        // 1 -> 1
                        if (aLong % 3 == 0) {
                            collector.collect(aLong + " -> " + aLong * aLong);
                            return;
                        }
                        // 1 -> 2
                        if (aLong % 5 == 0) {
                            collector.collect(aLong + " -> " + aLong);
                            collector.collect(aLong + " -> " + (-aLong));
                        }
                        // å…¶ä»– 1 -> 0
                    }
                })
                .print();

        env.execute("flatMap");
    }

    /**
     * 3. filter æ“ä½œ    è¿‡æ»¤
     */
    @Test
    public void filter() throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStreamSource<Long> source = env.fromSequence(1, 10);
        source
                .filter(x -> x % 2 == 0)
                .print();

        env.execute("filter");
    }

    /**
     * 4. connect æ“ä½œ ï¼Œå°†ä¸¤ä¸ªæµæ”¾åˆ°ä¸€èµ·ï¼Œè¿”å›ä¸€ä¸ª ConnectedStreamï¼Œä½†ä¸¤ä¸ªæµå…¶å®ä¾ç„¶ç‹¬ç«‹
     *
     * å¦‚æœåç»­è¿˜è¦å¯¹ ConnectedStream è¿›è¡Œ map ï¼ˆå…¶å®æ˜¯ CoMap äº†ï¼‰ã€flatMap (å…¶å®æ˜¯ CoFlatMap äº†) ç­‰æ“ä½œï¼Œå¿…é¡»ä¼ å…¥ä¸¤ä¸ªå¯¹åº”çš„å¤„ç†æ–¹æ³•ï¼Œåˆ†åˆ«å¯¹è¿æ¥å‰çš„æµ1ã€æµ2 è¿›è¡Œå¤„ç†
     * ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿æ¥åçš„æµï¼Œå†…éƒ¨å…¶å®ä¾ç„¶ä¿æŒç‹¬ç«‹ï¼
     */
    @Test
    public void connect() throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStreamSource<Long> stream01 = env.fromSequence(1, 10);
        DataStreamSource<String> stream02 = env.readTextFile("data/hello-world.txt");

        ConnectedStreams<Long, String> connected = stream01
                .connect(stream02);

        // æ³¨æ„ç±»å‹ CoMapFunction
        connected.map(new CoMapFunction<Long, String, Object>() {

            // è¿™é‡Œå®ç°å¯¹è¿æ¥å‰çš„ æµ1 çš„æ“ä½œ
            @Override
            public Object map1(Long aLong) throws Exception {
                return aLong * 2;
            }

            // è¿™é‡Œå®ç°å¯¹è¿æ¥å‰çš„ æµ2 çš„æ“ä½œ
            @Override
            public Object map2(String s) throws Exception {
                return ":2:" + s;
            }
        })
                .print()
        ;


        env.execute("connect");
    }


    /**
     * 5. split & select æ“ä½œï¼Œæ‹†åˆ†ã€é€‰æ‹©        <br />
     * ï¼ˆå¯æ€œï¼Œåœ¨ 1.13.1 ç‰ˆæœ¬ä¸­è¢«åˆ é™¤äº†ï¼ŒåŸå›   ï¼š      <br />
     *  è¢«åˆ é™¤çš„åŸå›   <br />
     * DataStream#split() has been deprecated in favour of using Side Outputs because:
     *
     * It is less performant, split() creates and checks against Strings for the splitting logic.
     * split() was and is buggy : see FLINK-5031 and FLINK-11084, for example
     * The semantics of consecutive splits are not very clear in general.
     * Side outputs are more general and everything that could be done using split() can be achieved with side
     * outputs with strictly better performance.
     * é€šä¿—ç‚¹å°±æ˜¯
     * æ€§èƒ½ä¸å¥½,ä¸ºå•¥æ€§èƒ½ä¸å¥½,æˆ‘ä¹Ÿæ²¡æœ‰çœ‹æ‡‚,å¦‚æœå„ä½æœ‰çœ‹æ‡‚çš„,è¯·ç§ä¿¡æˆ‘
     * splitå‡½æ•°æœ‰å¥½å‡ ä¸ªbug
     * ï¼‰
     */
    @Test
    public void split_select() throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStreamSource<Long> source = env.fromSequence(1, 10);

        // split & select å·²è¢«åˆ é™¤ï¼Œæ¨èä½¿ç”¨ Side outputs

        env.execute("split_select");
    }

    /**
     * 6. union æ“ä½œ  å°†ä¸¤ä¸ª DataStream åˆå¹¶æˆä¸€ä¸ª DataStream  ï¼Œæ³¨æ„å’Œ connect çš„åŒºåˆ«
     */
    @Test
    public void union() throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStream<Long> dataStream01 = env.fromSequence(1, 4);
        DataStream<Long> dataStream02 = env.fromSequence(20, 25);

        DataStream<Long> union = dataStream01
                .union(dataStream02);

        union.print();

        env.execute("union");
    }

}
